{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy\n",
    "pandas\n",
    "scipy\n",
    "scikit-learn\n",
    "matplotlib\n",
    "spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is meant to conduct all the preprocessing. \n",
    "\n",
    "### Specifically, we take raw ocr outputs from the PDFs, and convert them into count and tfidf vector representations suitable for a range of analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DOCS = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load In Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "      <th>population_year</th>\n",
       "      <th>...</th>\n",
       "      <th>ghg_reduction_target</th>\n",
       "      <th>target_year</th>\n",
       "      <th>percent_reduction</th>\n",
       "      <th>initiatives_committed</th>\n",
       "      <th>net_zero_target_status</th>\n",
       "      <th>econ_wide_net_zero</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>emis_per_capita</th>\n",
       "      <th>coordinator_name</th>\n",
       "      <th>support_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>Region</td>\n",
       "      <td>Aberdeenshire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>6313.00</td>\n",
       "      <td>57.166667</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>243510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GlobalCovenantofMayors2019</td>\n",
       "      <td>2,4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.572786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Convention of Scottish Local Authorities, GB</td>\n",
       "      <td>Supporter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBR</td>\n",
       "      <td>Region</td>\n",
       "      <td>Aberdeenshire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>6313.00</td>\n",
       "      <td>57.166667</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>243510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>20.0</td>\n",
       "      <td>GlobalCovenantofMayors2019</td>\n",
       "      <td>2,4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.572786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Energy Saving Trust</td>\n",
       "      <td>Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ITA</td>\n",
       "      <td>City</td>\n",
       "      <td>Acquappesa</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>14.45</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32% below 2014 levels by 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>32.0</td>\n",
       "      <td>EUCovenantofMayors2019;GlobalCovenantofMayors2...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.242215</td>\n",
       "      <td>4.556626</td>\n",
       "      <td>Energia Calabria Network</td>\n",
       "      <td>Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITA</td>\n",
       "      <td>City</td>\n",
       "      <td>Acquappesa</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>14.45</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100% below 2014 levels by Long term</td>\n",
       "      <td>Long term</td>\n",
       "      <td>100.0</td>\n",
       "      <td>EUCovenantofMayors2019;GlobalCovenantofMayors2...</td>\n",
       "      <td>1,4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.242215</td>\n",
       "      <td>4.556626</td>\n",
       "      <td>Energia Calabria Network</td>\n",
       "      <td>Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>City</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australia</td>\n",
       "      <td>East Asia and the Pacific</td>\n",
       "      <td>3257.70</td>\n",
       "      <td>-34.928889</td>\n",
       "      <td>138.601111</td>\n",
       "      <td>1376601.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.341376</td>\n",
       "      <td>0.834017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>BEL</td>\n",
       "      <td>City</td>\n",
       "      <td>Ville de Nivelles</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.597890</td>\n",
       "      <td>4.323399</td>\n",
       "      <td>28535.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>90% below 2006 levels by Long term</td>\n",
       "      <td>Long term</td>\n",
       "      <td>90.0</td>\n",
       "      <td>EUCovenantofMayors2020</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.474211</td>\n",
       "      <td>Région wallonne</td>\n",
       "      <td>Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ITA</td>\n",
       "      <td>City</td>\n",
       "      <td>Vogogna</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Europe</td>\n",
       "      <td>15.62</td>\n",
       "      <td>46.008980</td>\n",
       "      <td>8.293017</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93% below 2010 levels by 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>93.0</td>\n",
       "      <td>GlobalCovenantofMayors2019;EUCovenantofMayors2...</td>\n",
       "      <td>1,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.316261</td>\n",
       "      <td>4.181376</td>\n",
       "      <td>Region of Piemonte</td>\n",
       "      <td>Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>AUS</td>\n",
       "      <td>City</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>Australia</td>\n",
       "      <td>East Asia and the Pacific</td>\n",
       "      <td>572.20</td>\n",
       "      <td>-34.433060</td>\n",
       "      <td>150.883100</td>\n",
       "      <td>208875.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...</td>\n",
       "      <td>2,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365.038448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>AUS</td>\n",
       "      <td>City</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>Australia</td>\n",
       "      <td>East Asia and the Pacific</td>\n",
       "      <td>572.20</td>\n",
       "      <td>-34.433060</td>\n",
       "      <td>150.883100</td>\n",
       "      <td>208875.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...</td>\n",
       "      <td>2,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365.038448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>AUS</td>\n",
       "      <td>City</td>\n",
       "      <td>Wollongong</td>\n",
       "      <td>Australia</td>\n",
       "      <td>East Asia and the Pacific</td>\n",
       "      <td>572.20</td>\n",
       "      <td>-34.433060</td>\n",
       "      <td>150.883100</td>\n",
       "      <td>208875.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...</td>\n",
       "      <td>2,4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365.038448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso entity_type               name         country  \\\n",
       "0    GBR      Region      Aberdeenshire  United Kingdom   \n",
       "1    GBR      Region      Aberdeenshire  United Kingdom   \n",
       "2    ITA        City         Acquappesa           Italy   \n",
       "3    ITA        City         Acquappesa           Italy   \n",
       "4    AUS        City           Adelaide       Australia   \n",
       "..   ...         ...                ...             ...   \n",
       "569  BEL        City  Ville de Nivelles         Belgium   \n",
       "570  ITA        City            Vogogna           Italy   \n",
       "571  AUS        City         Wollongong       Australia   \n",
       "572  AUS        City         Wollongong       Australia   \n",
       "573  AUS        City         Wollongong       Australia   \n",
       "\n",
       "                        region     area        lat         lng  population  \\\n",
       "0                       Europe  6313.00  57.166667   -2.666667    243510.0   \n",
       "1                       Europe  6313.00  57.166667   -2.666667    243510.0   \n",
       "2                       Europe    14.45  39.500000   15.950000      1882.0   \n",
       "3                       Europe    14.45  39.500000   15.950000      1882.0   \n",
       "4    East Asia and the Pacific  3257.70 -34.928889  138.601111   1376601.0   \n",
       "..                         ...      ...        ...         ...         ...   \n",
       "569                     Europe      NaN  50.597890    4.323399     28535.0   \n",
       "570                     Europe    15.62  46.008980    8.293017      1770.0   \n",
       "571  East Asia and the Pacific   572.20 -34.433060  150.883100    208875.0   \n",
       "572  East Asia and the Pacific   572.20 -34.433060  150.883100    208875.0   \n",
       "573  East Asia and the Pacific   572.20 -34.433060  150.883100    208875.0   \n",
       "\n",
       "     population_year  ...                 ghg_reduction_target  target_year  \\\n",
       "0                NaN  ...                                  NaN         2020   \n",
       "1                NaN  ...                                  NaN         2020   \n",
       "2             2018.0  ...        32% below 2014 levels by 2020         2020   \n",
       "3             2018.0  ...  100% below 2014 levels by Long term    Long term   \n",
       "4             2017.0  ...                                  NaN         2020   \n",
       "..               ...  ...                                  ...          ...   \n",
       "569              NaN  ...   90% below 2006 levels by Long term    Long term   \n",
       "570           2010.0  ...        93% below 2010 levels by 2020         2020   \n",
       "571           2017.0  ...                                  NaN         2030   \n",
       "572           2017.0  ...                                  NaN          NaN   \n",
       "573           2017.0  ...                                  NaN         2050   \n",
       "\n",
       "    percent_reduction                              initiatives_committed  \\\n",
       "0                20.0                         GlobalCovenantofMayors2019   \n",
       "1                20.0                         GlobalCovenantofMayors2019   \n",
       "2                32.0  EUCovenantofMayors2019;GlobalCovenantofMayors2...   \n",
       "3               100.0  EUCovenantofMayors2019;GlobalCovenantofMayors2...   \n",
       "4                35.0  Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...   \n",
       "..                ...                                                ...   \n",
       "569              90.0                             EUCovenantofMayors2020   \n",
       "570              93.0  GlobalCovenantofMayors2019;EUCovenantofMayors2...   \n",
       "571               NaN  Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...   \n",
       "572               NaN  Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...   \n",
       "573               NaN  Carbonn2019;GlobalCovenantofMayors2019;CDPCiti...   \n",
       "\n",
       "    net_zero_target_status  econ_wide_net_zero pop_density emis_per_capita  \\\n",
       "0                      2,4                 1.0   38.572786             NaN   \n",
       "1                      2,4                 1.0   38.572786             NaN   \n",
       "2                        4                 1.0  130.242215        4.556626   \n",
       "3                      1,4                 1.0  130.242215        4.556626   \n",
       "4                      NaN                 1.0    7.341376        0.834017   \n",
       "..                     ...                 ...         ...             ...   \n",
       "569                    1,4                 NaN         NaN        8.474211   \n",
       "570                    1,4                 NaN  113.316261        4.181376   \n",
       "571                    2,4                 NaN  365.038448             NaN   \n",
       "572                    2,4                 NaN  365.038448             NaN   \n",
       "573                    2,4                 NaN  365.038448             NaN   \n",
       "\n",
       "                                 coordinator_name  support_type  \n",
       "0    Convention of Scottish Local Authorities, GB     Supporter  \n",
       "1                             Energy Saving Trust   Coordinator  \n",
       "2                        Energia Calabria Network   Coordinator  \n",
       "3                        Energia Calabria Network   Coordinator  \n",
       "4                                             NaN           NaN  \n",
       "..                                            ...           ...  \n",
       "569                               Région wallonne   Coordinator  \n",
       "570                            Region of Piemonte   Coordinator  \n",
       "571                                           NaN           NaN  \n",
       "572                                           NaN           NaN  \n",
       "573                                           NaN           NaN  \n",
       "\n",
       "[574 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Master CSV: https://github.com/datadrivenenvirolab/net_zero/blob/master/data/Sidd/net_zero_NLP_metadata_master.csv\n",
    "csv_path = '/Users/siddharthsachdeva/Downloads/net_zero_NLP_metadata_master.csv'\n",
    "# csv_path = 'sample_data/sample_meta.csv'\n",
    "meta = pd.read_csv(csv_path)\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Downlodunzip this data: https://drive.google.com/file/d/1hnoyLCcnNJub22YCHN5xxKHRy6Z8VqUw/view?usp=sharing\n",
    "extraction_path = '/Users/siddharthsachdeva/personal/carbon_zero_nlp/data/all_netzero_data_textract20200906/'\n",
    "# extraction_path = 'sample_data/text_jsons'\n",
    "city_names = set(meta.name)\n",
    "pdf_fnames = [name for name in os.listdir(extraction_path) \n",
    "              if name.endswith('.json')]\n",
    "len(pdf_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "\n",
    "# for f in pdf_fnames:\n",
    "#     copyfile(os.path.join(extraction_path, f),os.path.join(sample_extraction_path,f)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abasan Al-Kabira_textract20200906.json',\n",
       " 'Adelaide_carbon-neutral-action-plan (1)_textract20200906.json',\n",
       " 'Adelaide_report-carbon-neutral-adelaide-status-report-july-19_textract20200906.json',\n",
       " 'Alameda, CA_textract20200906.json',\n",
       " 'Albany, NY_textract20200906.json',\n",
       " 'Amman_textract20200906.json',\n",
       " 'Amsterdam_textract20200906.json',\n",
       " 'Ann Arbor, MI_textract20200906.json',\n",
       " 'Arlington, VA_textract20200906.json',\n",
       " 'ArlingtonFinal-CEP-CLEAN-003_textract20200906.json',\n",
       " 'Asheville, NC_textract20200906.json',\n",
       " 'Aspen, CO_textract20200906.json',\n",
       " 'Atlanta, GA_textract20200906.json',\n",
       " 'Auckland_textract20200906.json',\n",
       " 'Austin, TX_textract20200906.json',\n",
       " 'BCP Council_textract20200906.json',\n",
       " 'Barcelona_Climate_Plan_textract20200906.json',\n",
       " 'Barcelona_textract20200906.json',\n",
       " 'Bath & North East Somerset Climate Emergency Action Plan_textract20200906.json',\n",
       " 'Bath & North East Somerset_textract20200906.json',\n",
       " 'Belo Horizonte_textract20200906.json',\n",
       " 'Berkeley_CA_2020-07-21 Special Item 05 Climate Action Plan (1)_textract20200906.json',\n",
       " 'Berlin Climate Neutral_textract20200906.json',\n",
       " 'Berlin Climate Strategy_textract20200906.json',\n",
       " 'Blacksburg, VA_textract20200906.json',\n",
       " 'Boston, MA_textract20200906.json',\n",
       " 'Boulder County, CO_textract20200906.json',\n",
       " 'Boulder, CO_textract20200906.json',\n",
       " \"Bristol_UK_Mayor's Climate Emergency Action Plan 2019 FINAL_textract20200906.json\",\n",
       " 'Bristol_UK_Mayor_s Climate Emergency Action Plan 2019 FINAL_textract20200906.json',\n",
       " 'Bristol_UK_one-city-climate-strategy_textract20200906.json',\n",
       " 'Buenos Aires_textract20200906.json',\n",
       " 'Burlingame, CA_textract20200906.json',\n",
       " 'Burlington, VT_textract20200906.json',\n",
       " 'Bursa_textract20200906.json',\n",
       " 'Byron Shire_textract20200906.json',\n",
       " 'Calgary climate-resilience-plan_textract20200906.json',\n",
       " 'Calgary_imagineCALGARY_textract20200906.json',\n",
       " 'Cambridge, MA_textract20200906.json',\n",
       " 'Cape Town_textract20200906.json',\n",
       " 'Charlotte, NC_textract20200906.json',\n",
       " 'Charlotte_NC_SEAP - Executive Summary Full Doc FINAL_textract20200906.json',\n",
       " 'Chicago_CAP_textract20200906.json',\n",
       " 'Cincinnati, OH_textract20200906.json',\n",
       " 'City of Santa Cruz Climate Action Plan_textract20200906.json',\n",
       " 'Cleveland, OH_textract20200906.json',\n",
       " 'Columbia_MO_ADOPTED_CAAP_textract20200906.json',\n",
       " 'Columbus, OH_textract20200906.json',\n",
       " 'Copenhagen_cph-2025-climate-plan-2016pdf-_1586_textract20200906.json',\n",
       " 'Cupertino Climate Action Plan_textract20200906.json',\n",
       " 'Dallas, TX_textract20200906.json',\n",
       " 'Davis, CA_textract20200906.json',\n",
       " 'Denver, CO_textract20200906.json',\n",
       " 'Denver_CO_DDPHE_80x50_ClimateActionPlan_textract20200906.json',\n",
       " 'Dublin, CA_textract20200906.json',\n",
       " 'Eau Claire, WI_textract20200906.json',\n",
       " 'Edina, MN_textract20200906.json',\n",
       " 'Edmonton, AB_textract20200906.json',\n",
       " 'Elsinore_textract20200906.json',\n",
       " 'Emeryville CAP 2016 Final_textract20200906.json',\n",
       " 'Emeryville, CA_textract20200906.json',\n",
       " 'Erie County, NY_textract20200906.json',\n",
       " 'Espoo_textract20200906.json',\n",
       " 'Eugene, OR_textract20200906.json',\n",
       " 'Eugene_OR_CAP 2.0_Summer_2020_FINAL (003) w appendices compressed_textract20200906.json',\n",
       " 'Evanston, IL_textract20200906.json',\n",
       " 'Flagstaff_AZ_Climate Action and Adaptation Plan_12-10-18_201812101421377189_textract20200906.json',\n",
       " 'Fort Collins, CO_textract20200906.json',\n",
       " 'Fremont, CA Resolution_textract20200906.json',\n",
       " 'Glasgow_textract20200906.json',\n",
       " 'Greater Manchester_textract20200906.json',\n",
       " 'Guelph_textract20200906.json',\n",
       " 'Halifax_textract20200906.json',\n",
       " 'Hayward, CA_textract20200906.json',\n",
       " 'Heidelberg_textract20200906.json',\n",
       " 'Hong Kong_textract20200906.json',\n",
       " 'Houston, TX_textract20200906.json',\n",
       " 'Houston_TX_CAP-April2020_textract20200906.json',\n",
       " 'Høje-Taastrup_textract20200906.json',\n",
       " 'Indianapolis, IN_textract20200906.json',\n",
       " 'Kampala Climate Change Action_textract20200906.json',\n",
       " 'Kansas, MO_textract20200906.json',\n",
       " 'Knoxville_TN_sustaining-success_textract20200906.json',\n",
       " 'Kristianstad_textract20200906.json',\n",
       " 'KwaDukuza_textract20200906.json',\n",
       " 'LA_CA_pLAn_2019_final_textract20200906.json',\n",
       " 'Lexington, MA_textract20200906.json',\n",
       " 'Lisbon_modelo_plano_acao_energias_sustentaveis_clima_textract20200906.json',\n",
       " 'Lisbon_textract20200906.json',\n",
       " 'Ljubljana_textract20200906.json',\n",
       " 'London, UK_textract20200906.json',\n",
       " 'London_ON_Community Energy Plan_textract20200906.json',\n",
       " 'London_UK_1.5c_compatible_plan_textract20200906.json',\n",
       " 'London_UK_zero-emissions-city-2018_textract20200906.json',\n",
       " 'Louiseville_KY_ghg_erp_final_draft_20200422_0_textract20200906.json',\n",
       " 'Louisiana JBE-2020-18-Climate-Initiatives-Task-Force_textract20200906.json',\n",
       " 'Louisville, KY_textract20200906.json',\n",
       " 'Manchester_textract20200906.json',\n",
       " 'Medford, MA_textract20200906.json',\n",
       " 'Melbourne_climate-change-mitigation-strategy-2050_textract20200906.json',\n",
       " 'Melbourne_textract20200906.json',\n",
       " 'Mexico_City_PACCM-ingles_textract20200906.json',\n",
       " 'Mississauga Climate Change Action Plan_textract20200906.json',\n",
       " 'Mississauga_textract20200906.json',\n",
       " 'Mornington Peninsula_textract20200906.json',\n",
       " 'New Bedford, MA_textract20200906.json',\n",
       " 'New Orleans_LA_Climate-Action-for-a-Resilient-New-Orleans_textract20200906.json',\n",
       " 'New York City, NY_textract20200906.json',\n",
       " 'Northhampton_textract20200906.json',\n",
       " 'Orebro_textract20200906.json',\n",
       " 'Orlando, FL_textract20200906.json',\n",
       " 'Orlando_FL_2018_orlando_communityactionplan_textract20200906.json',\n",
       " 'Oslo_textract20200906.json',\n",
       " 'Palo Alto, CA Framework_textract20200906.json',\n",
       " 'Palo Alto, CA_textract20200906.json',\n",
       " 'Paris_textract20200906.json',\n",
       " 'Philadelphia, PA_textract20200906.json',\n",
       " 'Philadelphia_PA_Powering-Our-Future-Full-Report_textract20200906.json',\n",
       " 'Piedmont, CA_textract20200906.json',\n",
       " 'Pittsburgh, PA_textract20200906.json',\n",
       " 'Pittsburgh_PA_Climate_Action_Plan_3.0_textract20200906.json',\n",
       " 'Plymouth, UK_textract20200906.json',\n",
       " 'Portland_OR_cap-2015_june30-2015_web_0_textract20200906.json',\n",
       " 'Providence, RI_textract20200906.json',\n",
       " 'Providence_RI_Climate-Justice-Plan-Report-FINAL-English-1_textract20200906.json',\n",
       " 'Reykjavík_textract20200906.json',\n",
       " 'Riga_textract20200906.json',\n",
       " 'Sacramento, CA_textract20200906.json',\n",
       " 'Salt Lake City, UT_textract20200906.json',\n",
       " 'San Carlos_textract20200906.json',\n",
       " 'San Francisco, CA_textract20200906.json',\n",
       " 'San Francisco_CA_ClimateActionStrategyUpdate2013_textract20200906.json',\n",
       " 'San Jose, CA_textract20200906.json',\n",
       " 'San Jose_CA_ClimateSmartSanJose_070218_textract20200906.json',\n",
       " 'Santa Cruz_FinalCAP_textract20200906.json',\n",
       " 'Santiago Action Plan -COP25 - final_textract20200906.json',\n",
       " 'Sarasota, FL-2_textract20200906.json',\n",
       " 'Sarasota, FL_textract20200906.json',\n",
       " 'Saskatoon_textract20200906.json',\n",
       " 'Singapore_textract20200906.json',\n",
       " 'Skovde_textract20200906.json',\n",
       " 'Somerville, MA_textract20200906.json',\n",
       " 'Sonama, CA_textract20200906.json',\n",
       " 'St Catharines _ON_CDMP-Final-190826_textract20200906.json',\n",
       " 'St Louis, MO_textract20200906.json',\n",
       " 'St Louis_MO_v1-1-CAP_FINAL_textract20200906.json',\n",
       " 'Stockholm_strategy-for-a-fossil-fuel-free-stockholm-by-2040_textract20200906.json',\n",
       " 'Stockholm_textract20200906.json',\n",
       " 'Sydney_textract20200906.json',\n",
       " 'Tacoma, WA 2019_textract20200906.json',\n",
       " 'Tacoma, WA_textract20200906.json',\n",
       " 'Tacoma_EAP_textract20200906.json',\n",
       " 'Tainan City Climate Action 2016_textract20200906.json',\n",
       " 'Tainan_textract20200906.json',\n",
       " 'The Espoo Story in English_textract20200906.json',\n",
       " 'Tokyo_textract20200906.json',\n",
       " 'Toronto, TransformTO_textract20200906.json',\n",
       " 'Trondheim_textract20200906.json',\n",
       " 'Turku_textract20200906.json',\n",
       " 'Umea_textract20200906.json',\n",
       " 'Uppsala_textract20200906.json',\n",
       " 'Upssala Climate and Energy Programme 2014-2023_textract20200906.json',\n",
       " 'Urbana, IL Resolution_textract20200906.json',\n",
       " 'Vancouver, BC_textract20200906.json',\n",
       " 'Victoria Climate Action Plan_textract20200906.json',\n",
       " 'Victoria_textract20200906.json',\n",
       " 'Västervik_textract20200906.json',\n",
       " 'Washington D.C._textract20200906.json',\n",
       " 'Winnipeg, MB_textract20200906.json',\n",
       " 'Wollongong_textract20200906.json',\n",
       " 'Wyndham_textract20200906.json',\n",
       " 'eThekweni_textract20200906.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(pdf_fnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format OCR output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for fname in pdf_fnames:\n",
    "    city_name = fname.split(',')[0].split('_')[0]\n",
    "    path = os.path.join(extraction_path, fname)\n",
    "    with open(path, 'r') as f:\n",
    "        text_json = json.load(f)\n",
    "        if text_json['-1'] is not None:\n",
    "            raw_text = text_json['-1']['raw_text']\n",
    "            ocr_method = text_json['-1']['method']\n",
    "            translated_text = text_json['-1'].get('translated_text', None)\n",
    "        else:\n",
    "            raw_text = None\n",
    "            ocr_method = None\n",
    "        row = {\n",
    "            'full_json': json.dumps(text_json),\n",
    "            'raw_text': raw_text,\n",
    "            'translated_text': translated_text,\n",
    "            'ocr_method': ocr_method,\n",
    "            'city': city_name,\n",
    "            'path': path\n",
    "        }\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip this data: https://drive.google.com/file/d/1O-bGar07viUpuaxbp8PHmQ0oFQhiRpdZ/view?usp=sharing\n",
    "\n",
    "translated_extraction_path = '/Users/siddharthsachdeva/personal/carbon_zero_nlp/data/eucovdata_textracttesseract_translated/'\n",
    "translated_pdf_fnames = [name for name in os.listdir(translated_extraction_path) if name.endswith('.json')]\n",
    "                         #and name.split(' -')[0] in full_ds.name.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aalborg - Climate Strategy_tesseract20200906.json',\n",
       " 'Aarhus - Climate Plan 2016-2020 _tesseract20200906.json',\n",
       " 'Aberdeenshire - Net Zero Vision And Infrastructure Plan _tesseract20200906.json',\n",
       " 'Acquappesa - SEAP (Italian) _tesseract20200906.json',\n",
       " 'Albairate - PAES (Italian) _tesseract20200906.json',\n",
       " 'Albertslund - Klimastrategi 2017-2025 (Danish) _tesseract20200906.json',\n",
       " 'Alessano - Alessano Sostenibile (Italian) _tesseract20200906.json',\n",
       " 'Andrano - Andrano 2020 (Italian) _tesseract20200906.json',\n",
       " 'Arzana - Action Plan Local Arzana Elini (Italian) _tesseract20200906.json',\n",
       " 'Asse - Klimaatactieplan Asse (Dutch) _tesseract20200906.json',\n",
       " 'Averara - SEAP Averara (Italian) _tesseract20200906.json',\n",
       " 'Bagnoli di Sopra - PAES (Italian) _tesseract20200906.json',\n",
       " 'Bagnolo San Vito - PAES (Italian) _tesseract20200906.json',\n",
       " 'Balones - SEAP Of Balones (Spanish) _tesseract20200906.json',\n",
       " 'Balsareny - PAES De Balsareny (Catalan) _tesseract20200906.json',\n",
       " 'Balti - Sustainable Energy And Climate Action Plan (SECAP)  6.57.25 PM_tesseract20200906.json',\n",
       " 'Balti - Sustainable Energy And Climate Action Plan (Secap) _tesseract20200906.json',\n",
       " 'Basso Sulcis - PAES Dei Comuni Del Basso Sulcis (Italian) _tesseract20200906.json',\n",
       " 'Beersel - Klimaatplan Beersel (Dutch) _tesseract20200906.json',\n",
       " 'Belfiore - PAES (Italian) _tesseract20200906.json',\n",
       " 'Belvì - Belvi_ Sostenibile (Italian) _tesseract20200906.json',\n",
       " 'Beniardà - SEAP Of Beniard (Spanish) _tesseract20200906.json',\n",
       " 'Berlin - Energy Concept 2020 (German) _tesseract20200906.json',\n",
       " 'Bila Tserkva - Sustainable Energy And Climate Action Plan For The City Of Bila Tserkva For The Period 2017-2030 (Russian) _tesseract20200906.json',\n",
       " 'Birmingham, UK - SEAP_tesseract20200906.json',\n",
       " 'Bolzano - PAES Di Bolzano (Italian)_tesseract20200906.json',\n",
       " 'Bornova - Enerji Eylem Plan (Turkish)_tesseract20200906.json',\n",
       " 'Botkyrka - Strategi F̦R Energieffektivisering Botkyrka Kommun (Swedish)_tesseract20200906.json',\n",
       " 'Bracca - SEAP Bracca (Italian)_tesseract20200906.json',\n",
       " 'Braslau - SEAP (Russian) _tesseract20200906.json',\n",
       " 'Breda, Netherlands - 2017-2020 Climate Implementation Programme _tesseract20200906.json',\n",
       " 'Brugge - Energie Actieplan Brugge (Dutch) _tesseract20200906.json',\n",
       " 'Budapest Fováros XIX. Kerület, Kispest Önkormányzata - Kispest Fenntarthat_ Energia- _S Kl_Maakci_Terve (Hungarian) _tesseract20200906.json',\n",
       " 'Cajnice - Akcioni Plan Energijski Odr_Ivog Razvoja Op_Tine _Ajni_E (Serbian) _tesseract20200906.json',\n",
       " 'Carona - SEAP Carona (Italian) _tesseract20200906.json',\n",
       " 'Cartura - PAES Cartura (Italian) _tesseract20200906.json',\n",
       " 'Casalserugo - PAES Casalserugo (Italian) _tesseract20200906.json',\n",
       " 'Cervia - Cervia Citt_ Resiliente (Italian) _tesseract20200906.json',\n",
       " 'Cheremule - Energy Plan Cheremule (Italian)_tesseract20200906.json',\n",
       " 'Commune de Paliseul - Paedc Paliseul (French) _tesseract20200906.json',\n",
       " 'Comunità pioniera di Arborea - PAES - Comunit_ Pioniera Di Arborea (Italian) _tesseract20200906.json',\n",
       " 'Copenhagen - SEAP (Danish) _tesseract20200906.json',\n",
       " 'Corsano - Corsano Sostenibile - Verso Il 202 A Basse Emissioni Di Co2 (Italian) _tesseract20200906.json',\n",
       " 'Delft - Delft Energy Neutral 2050  _tesseract20200906.json',\n",
       " 'Dénia - SEAP Of Dnia (Spanish) _tesseract20200906.json',\n",
       " 'Dilbeek - Dilbeek Klimaatactieplan (Dutch) _tesseract20200906.json',\n",
       " 'Dossena - My SEAP Dossena (Italian) _tesseract20200906.json',\n",
       " 'Dundee - Dundee Climate Action Plan _tesseract20200906.json',\n",
       " 'Durbuy - PAEDC Durbuy (French) _tesseract20200906.json',\n",
       " 'Eilat ISRAEL - Eilat Municipality Plan To Reduce Greenhouse Gas Emission _tesseract20200906.json',\n",
       " 'Elini - Action Plan Local Arzana Elini (Italian) _tesseract20200906.json',\n",
       " 'Elsinore_textract20200906.json',\n",
       " 'Espoo - Climate Programme 2016-2020_tesseract20200906.json',\n",
       " 'Essen - Fortschreibung 2013 (German) _tesseract20200906.json',\n",
       " 'Fermo - SEAP_tesseract20200906.json',\n",
       " 'Fontanafredda - PAES Comune Di Fontanafredda (Italian) _tesseract20200906.json',\n",
       " 'Frankenthal - Integrated Climate Protection Concept _tesseract20200906.json',\n",
       " 'Frederikshavn - Masterplan For 100_ Re In 2030 _tesseract20200906.json',\n",
       " 'Gagliano del Capo - Gagliano Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) _tesseract20200906.json',\n",
       " 'Gela - Relazione Gela (Italian) _tesseract20200906.json',\n",
       " 'Genk - Klimaatplan 2030 (Dutch) _tesseract20200906.json',\n",
       " 'Giave - Energy Plan Giave (Italian) _tesseract20200906.json',\n",
       " 'Gorga - SEAP Of Gorga (Spanish) _tesseract20200906.json',\n",
       " 'Gothenburg - The Energy Efficient City _tesseract20200906.json',\n",
       " 'Granze (Pd) - Italy - PAES Granze (Italian) _tesseract20200906.json',\n",
       " 'Groningen - Groningen Energizes _tesseract20200906.json',\n",
       " 'Haarlem - Gemeentelijke Co2-Monitor (Dutch) _tesseract20200906.json',\n",
       " 'Halle - Halle(N) In Actie Voor Het Klimaat! (Dutch) _tesseract20200906.json',\n",
       " 'Hanau - Kommunales Klimaschutzkonzept Hanau (German) _tesseract20200906.json',\n",
       " 'Hannover - SEAP (German) _tesseract20200906.json',\n",
       " 'Hebron - Hebron SEAP _tesseract20200906.json',\n",
       " 'Heidelberg - Co2-Bilanzierung 2012 Bis 2015 Sowie Evaluation Des Masterplan 100_ Klimaschutz (German) _tesseract20200906.json',\n",
       " 'Helsinki - Kest_V_N Energiank_YțN Toimenpideohjelma (Finnish) _tesseract20200906.json',\n",
       " 'Herbeumont - PAEDC Herbeumont (French) _tesseract20200906.json',\n",
       " 'Hlybokaje - SEAP (Russian) _tesseract20200906.json',\n",
       " 'Høje-Taastrup_textract20200906.json',\n",
       " 'Ios (Aegean Islands) - SEAP (Greek) _tesseract20200906.json',\n",
       " 'Isola D’Elba - PAES Isola D_Elba _tesseract20200906.json',\n",
       " 'Isola di Fondra - SEAP Isola Di Fondra (Italian) _tesseract20200906.json',\n",
       " 'Izegem - Goedgekeurd SECAP (Dutch) _tesseract20200906.json',\n",
       " 'Jászberény Városi Önkormányzat - Jszberny Fenntarthat Energia Akciterve (Hungarian) _tesseract20200906.json',\n",
       " 'Joensuu - SEAP Joensuu 2015 Update _tesseract20200906.json',\n",
       " 'Jolanda di Savoia - PAES (Italian) _tesseract20200906.json',\n",
       " 'Jurmala - SEAP For Jurmala City For 2013-2020 (Latvian) _tesseract20200906.json',\n",
       " 'Kaiserslautern - SEAP (German) _tesseract20200906.json',\n",
       " 'Kéa (Aegean Islands) - SEAP (Greek) _tesseract20200906.json',\n",
       " 'Kortenaken - Klimaatactieplan Kortenaken (Dutch) _tesseract20200906.json',\n",
       " 'Korthi (Aegean Islands) - SEAP (Greek) _tesseract20200906.json',\n",
       " 'Kozloduy - Energy Action Plan (Bulgarian) _tesseract20200906.json',\n",
       " 'Kristianstad_textract20200906.json',\n",
       " 'Krško - SEAP (Slovenian) _tesseract20200906.json',\n",
       " 'Kruibeke - Kruibeke Klimaatneutraal (Dutch) _tesseract20200906.json',\n",
       " 'Kungsbacka - Klimatstrategi For Kungsbacka Kommun (Swedish) _tesseract20200906.json',\n",
       " 'La Puebla de Cazalla - SEAP Of La Puebla De Cazalla (Sevilla - Spain) (Spanish) _tesseract20200906.json',\n",
       " 'Landen - Gemeentelijk Klimaatactieplan Landen (Dutch) _tesseract20200906.json',\n",
       " 'Las Torres de Cotillas - Firma Compromisos (Spanish) _tesseract20200906.json',\n",
       " 'Leeds - Leeds City Council SEAP _tesseract20200906.json',\n",
       " 'Lennik - Klimaatactieplan Gemeente Lennik (Dutch) _tesseract20200906.json',\n",
       " 'Lessebo - Energi, Milj Ochklimatstrategiskt Program (Swedish) _tesseract20200906.json',\n",
       " 'Leuven - SEAP (Dutch) _tesseract20200906.json',\n",
       " 'Liedekerke - Gemeentelijk Klimaatplan Liedekerke (Dutch) _tesseract20200906.json',\n",
       " 'Linter - Klimaatactieplan Gemeente Linter (Dutch) _tesseract20200906.json',\n",
       " 'Lipsi (Aagen Islands) - SEAP (Greek) _tesseract20200906.json',\n",
       " 'Lisbon - PAES De Lisboa (Portuguese) _tesseract20200906.json',\n",
       " 'Lisbon_modelo_plano_acao_energias_sustentaveis_clima_textract20200906.json',\n",
       " 'Loiri Porto San Paolo - Loiri Porto San Paolo Sostenibile (Italian) _tesseract20200906.json',\n",
       " 'Lörrach - Klimaneutrale Stadt Lorrach Endbericht (German) _tesseract20200906.json',\n",
       " 'Luleå - SEAP Lule (Swedish) _tesseract20200906.json',\n",
       " 'Macerata - PAES Del Comune Di Macerata (Italian) _tesseract20200906.json',\n",
       " 'Macerata Campania - PAES Macerata Campania (Italian) _tesseract20200906.json',\n",
       " 'Maldegem - SEAP Maldegem Actieplan (Dutch) _tesseract20200906.json',\n",
       " 'Maltepe - Maltepe Municipality SEAP (Turkish) _tesseract20200906.json',\n",
       " 'Mantova - Mantova SEAP Pubiished (Italian) _tesseract20200906.json',\n",
       " 'Menjez - Menjez, The Greenville _tesseract20200906.json',\n",
       " 'Merlara - PAES Merlara (Italian) _tesseract20200906.json',\n",
       " 'Mezzoldo - SEAP Document Mezzoldo (Italian) _tesseract20200906.json',\n",
       " 'Moio de Calvi - SEAP Mio De_ Calvi (Italian) _tesseract20200906.json',\n",
       " 'Monistrol de Calders - Pla D_Acci_ Per A L_Energia Sostenible De Monistrol De Calders (Catalan) _tesseract20200906.json',\n",
       " 'Monrupino-Repentabor - PAES Di Monte Di Malo (Italian) _tesseract20200906.json',\n",
       " 'Monte di Malo - PAES Di Monte Di Malo (Italian) _tesseract20200906.json',\n",
       " 'Montejícar - Informe De Seguimiento PAES 2012-2020 (Spanish) _tesseract20200906.json',\n",
       " 'Monteleone Rocca Doria - PAES (Italian) _tesseract20200906.json',\n",
       " 'Monterenzio - PAES Monterenzio (Italian) _tesseract20200906.json',\n",
       " 'Morciano di Leuca - Morciano Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) _tesseract20200906.json',\n",
       " 'Moruzzo - Relazione Tecnico Illustrativa (Italian)_tesseract20200906.json',\n",
       " 'Moura - SEAP Moura (Portuguese) _tesseract20200906.json',\n",
       " 'Münster - SEAP (German) _tesseract20200906.json',\n",
       " 'Nablus - Nablus SEAP _tesseract20200906.json',\n",
       " 'Nevele - Duurzaam Energieactieplan Gemeente Nevele (Dutch) _tesseract20200906.json',\n",
       " 'Nikopol - SEAP_Nikopol (Russian) _tesseract20200906.json',\n",
       " 'Nilüfer - SEAP Monitoring Report (Dutch) _tesseract20200906.json',\n",
       " 'Nisyros (Aegean Islands) - SEAP (Greek) _tesseract20200906.json',\n",
       " 'Offida - Sustainable Energy And Climate Action Plan - Mitigation (Italian) _tesseract20200906.json',\n",
       " 'Orebro_textract20200906.json',\n",
       " 'Ornica - SEAP Document Ornica (Italian) _tesseract20200906.json',\n",
       " 'Ossana - PAES Comune Di Ossana (Italian) _tesseract20200906.json',\n",
       " 'Oulu - SEAP Of Oulu Under Covenant Of Mayors (Finnish) _tesseract20200906.json',\n",
       " 'Oxford - Climate Emergency Strategy Support _tesseract20200906.json',\n",
       " 'Palma - Pla D_ Accio Per A L_ Energia Sostenible De Palma (Catalan) _tesseract20200906.json',\n",
       " 'Pantelleria - PAES Del Comune Di Pantelleria (Italian) _tesseract20200906.json',\n",
       " 'Paola - PAES (Italian) _tesseract20200906.json',\n",
       " 'Patù - Patu_ Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) _tesseract20200906.json',\n",
       " 'Pedro Abad - PAES (Spanish) _tesseract20200906.json',\n",
       " 'Pellizzano - PAES Comune Di Pellizzano (Italian) _tesseract20200906.json',\n",
       " 'Peñarroya-Pueblonuevo - Plan De Accin Por El Clima Y La Energa Sostenible (Spanish) _tesseract20200906.json',\n",
       " 'Piazzatorre - SEAP Document Piazzatorre (Italian) _tesseract20200906.json',\n",
       " 'Piazzolo - SEAP Document Piazzolo (Italian) _tesseract20200906.json',\n",
       " 'Pollina - Relazione Pollina (Italian) _tesseract20200906.json',\n",
       " 'Pontecchio Polesine - PAES Pontecchio Polesine (Italian) _tesseract20200906.json',\n",
       " 'Porsgrunn - Climate Actionplan For Grenland Included Industry (Norwegian) _tesseract20200906.json',\n",
       " 'Region Zuid-West-Vlaanderen - Regionaal Duurzame Energie Actieplan 2020 (Dutch) _tesseract20200906.json',\n",
       " 'Riga - Riga City SEAP (SEAP) For 2014-2020 _tesseract20200906.json',\n",
       " 'Riner - Pla D_Acci Per A L_Energia Sostenible De Riner (Catalan) _tesseract20200906.json',\n",
       " 'Ringkøbing-Skjern - Strategic Energy Plan For Ringkbing-Skjern Muncipality - Energy 2020 - 2015-2018 _tesseract20200906.json',\n",
       " 'Roncobello - SEAP Document Roncobello (Italian) _tesseract20200906.json',\n",
       " 'Roveredo In Piano - PAES Del Comune Di Roveredo In Piano - Relazione Tecnico-Illustrativa (Italian) _tesseract20200906.json',\n",
       " 'Saint-Nicolas - Plan D_Action En Faveur De L_Nergie Durable Et Du Climat (French) _tesseract20200906.json',\n",
       " 'Salve - Salve Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) _tesseract20200906.json',\n",
       " 'Samsø - SEAP Island Of Samso_tesseract20200906.json',\n",
       " 'San Giorgio di Nogaro - PAES Del Comune Di San Giorgio Di Nogaro - Relazione Tecnico Illustrativa (Italian) _tesseract20200906.json',\n",
       " 'San Isidro, Spain - SEAP Of San Isidro (Spanish) _tesseract20200906.json',\n",
       " 'San Pietro Viminario (Pd) - PAES San Pietro Viminario (Italian) _tesseract20200906.json',\n",
       " 'San Polo d_Enza - Piano Dazione Per Lenergia Sostenibile Del Comune Di San Polo Denza (Re) (Italian)_tesseract20200906.json',\n",
       " 'Sant_ Urbano - PAES Sant_Urbano (Italian) _tesseract20200906.json',\n",
       " 'Sant_Anna Arresi - Smart City  Comuni In Classe A (Italian) _tesseract20200906.json',\n",
       " 'Sant_Elena - PAES Sant_Elena (Italian) _tesseract20200906.json',\n",
       " 'Santa Brigida - SEAP Document Santa Brigida (Italian) _tesseract20200906.json',\n",
       " 'Santa Maria Nuova - Piano Dazione Per Lenergia Sostenibile Del Comune Di Santa Maria Nuova (Italian) _tesseract20200906.json',\n",
       " 'Sartirana Lomellina - PAES Del Comune Di Sartirana Lomellina (Italian)_tesseract20200906.json',\n",
       " 'Senigallia - SEAP Of Senigallia (Italian) _tesseract20200906.json',\n",
       " 'Serre - PAES Del Comune Di Serre  (Italian) _tesseract20200906.json',\n",
       " 'Seulo - PAES Della Comunit Di Seulo (Italian) _tesseract20200906.json',\n",
       " 'Skive - Klima _ Energi Handlingsplan 2020 (Danish) _tesseract20200906.json',\n",
       " 'Skovde_tesseract20200906.json',\n",
       " 'Skyros Island - SEAP Of Municipality Of Skyros (Greek) _tesseract20200906.json',\n",
       " 'Socchieve - PAES Del Comune Di Socchieve (Italian) _tesseract20200906.json',\n",
       " 'Solesino - PAES Solesino (Italian) _tesseract20200906.json',\n",
       " 'Somma Lombardo - Somma Lombardo SEAP (Italian) _tesseract20200906.json',\n",
       " 'Somoniyon - SEAP Of Somoniyon _tesseract20200906.json',\n",
       " 'South Tyneside - A SEAP For South Tyneside _tesseract20200906.json',\n",
       " 'Sønderborg - Projectzero Masterplan 2029 _tesseract20200906.json',\n",
       " 'Taleggio - PAES Comune Di Taleggio (Italian) _tesseract20200906.json',\n",
       " 'Tampere - Pormestareiden Ilmastositoumuksen Kestvn Energiankytn Ohjelma (Finnish) _tesseract20200906.json',\n",
       " 'Tàrbena - SEAP Of Trbena (Spanish) _tesseract20200906.json',\n",
       " 'Teulada - SEAP Of Teulada (Spanish) _tesseract20200906.json',\n",
       " 'Tibi - SEAP Of Tibi (Spanish) _tesseract20200906.json',\n",
       " 'Tilburg - Klimaataanpak 2013-2020 (Dutch) _tesseract20200906.json',\n",
       " 'Tirana - SEAP Of The City Of Tirana _tesseract20200906.json',\n",
       " 'Trondheim - SEAP (Norwegian) _tesseract20200906.json',\n",
       " 'Trondheim_textract20200906.json',\n",
       " 'Tulkarm - Tulkarem SEAP_tesseract20200906.json',\n",
       " 'Unione dei Comuni NET (Nord Est Torino) - SEAP Of The Union Of Municipalities (Italian) _tesseract20200906.json',\n",
       " 'Urbana - PAES Urbana (Italian) _tesseract20200906.json',\n",
       " 'Urbino - PAES Del Comune Di Urbino _tesseract20200906.json',\n",
       " 'Utrecht - Utrecht Energy Plan _tesseract20200906.json',\n",
       " 'Vaasa - City Of Vaasa SEAP (Finnish) _tesseract20200906.json',\n",
       " 'Valtorta - Sustaianble Energy Action Plan Valtorta (Italian) _tesseract20200906.json',\n",
       " 'Vantaa - Vantaan Kaupungin Kets_V_N Energiank_YțN Toimenpidesuunntelma (Finnish) _tesseract20200906.json',\n",
       " 'Växjö - Energy Plan For Vxj Municipality _tesseract20200906.json',\n",
       " 'Vedeseta - SEAP Vedeseta (Italian) _tesseract20200906.json',\n",
       " 'Vilkaviškis - SEAP _tesseract20200906.json',\n",
       " 'Villa Literno - PAES E Liternum (Italian) _tesseract20200906.json',\n",
       " 'Villa Verde - PAES Della Comunit Di Villa Verde (Italian) _tesseract20200906.json',\n",
       " 'Villanova Tulo - PAES (Italian) _tesseract20200906.json',\n",
       " 'Villasimius - PAES Della Comunit Di Villasimius (Italian) _tesseract20200906.json',\n",
       " 'Ville de Nivelles - Plan Dactions Nergie Durable _ Climat (French) _tesseract20200906.json',\n",
       " 'Vimodrone - PAES (Italian) _tesseract20200906.json',\n",
       " 'Vogogna - PAES Di Vogogna (Italian) _tesseract20200906.json',\n",
       " 'Västervik_textract20200906.json',\n",
       " 'Wallonie Picarde Energie Positive - Groupe Wallonie Picarde Energie Positive (French) _tesseract20200906.json',\n",
       " 'Wezembeek-Oppem - Gemeentelijk Klimaatactieplan (Dutch) _tesseract20200906.json',\n",
       " 'Ærø - Visionsplan For Rs Energiforsyning (Danish) _tesseract20200906.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(translated_pdf_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in translated_pdf_fnames:\n",
    "    city_name = fname.split(',')[0].split('_')[0]\n",
    "    path = os.path.join(translated_extraction_path, fname)\n",
    "    with open(path, 'r') as f:\n",
    "        text_json = json.load(f)\n",
    "        if text_json['-1'] is not None:\n",
    "            raw_text = text_json['-1']['raw_text']\n",
    "            ocr_method = text_json['-1']['method']\n",
    "            translated_text = text_json['-1'].get('translated_text', None)\n",
    "        else:\n",
    "            raw_text = None\n",
    "            ocr_method = None\n",
    "        row = {\n",
    "            'full_json': json.dumps(text_json),\n",
    "            'raw_text': raw_text,\n",
    "            'translated_text': translated_text,\n",
    "            'ocr_method': ocr_method,\n",
    "            'city': city_name,\n",
    "            'path': path\n",
    "        }\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "len(df['city'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albany, NY_textract20200906.json', 'BCP Council_textract20200906.json', 'Emeryville, CA_textract20200906.json', 'Orlando, FL_textract20200906.json', 'Riga_textract20200906.json']\n",
      "['Aalborg - Climate Strategy', 'Aarhus - Climate Plan 2016-2020 ', 'Abasan Al-Kabira', 'Aberdeenshire - Net Zero Vision And Infrastructure Plan ', 'Acquappesa - SEAP (Italian) ', 'Adelaide', 'Adelaide', 'Alameda', 'Albairate - PAES (Italian) ', 'Albany', 'Albertslund - Klimastrategi 2017-2025 (Danish) ', 'Alessano - Alessano Sostenibile (Italian) ', 'Amman', 'Amsterdam', 'Andrano - Andrano 2020 (Italian) ', 'Ann Arbor', 'Arlington', 'ArlingtonFinal-CEP-CLEAN-003', 'Arzana - Action Plan Local Arzana Elini (Italian) ', 'Asheville', 'Aspen', 'Asse - Klimaatactieplan Asse (Dutch) ', 'Atlanta', 'Auckland', 'Austin', 'Averara - SEAP Averara (Italian) ', 'BCP Council', 'Bagnoli di Sopra - PAES (Italian) ', 'Bagnolo San Vito - PAES (Italian) ', 'Balones - SEAP Of Balones (Spanish) ', 'Balsareny - PAES De Balsareny (Catalan) ', 'Balti - Sustainable Energy And Climate Action Plan (SECAP)  6.57.25 PM', 'Balti - Sustainable Energy And Climate Action Plan (Secap) ', 'Barcelona', 'Barcelona', 'Basso Sulcis - PAES Dei Comuni Del Basso Sulcis (Italian) ', 'Bath & North East Somerset', 'Bath & North East Somerset Climate Emergency Action Plan', 'Beersel - Klimaatplan Beersel (Dutch) ', 'Belfiore - PAES (Italian) ', 'Belo Horizonte', 'Belvì - Belvi', 'Beniardà - SEAP Of Beniard (Spanish) ', 'Berkeley', 'Berlin - Energy Concept 2020 (German) ', 'Berlin Climate Neutral', 'Berlin Climate Strategy', 'Bila Tserkva - Sustainable Energy And Climate Action Plan For The City Of Bila Tserkva For The Period 2017-2030 (Russian) ', 'Birmingham', 'Blacksburg', 'Bolzano - PAES Di Bolzano (Italian)', 'Bornova - Enerji Eylem Plan (Turkish)', 'Boston', 'Botkyrka - Strategi F̦R Energieffektivisering Botkyrka Kommun (Swedish)', 'Boulder', 'Boulder County', 'Bracca - SEAP Bracca (Italian)', 'Braslau - SEAP (Russian) ', 'Breda', 'Bristol', 'Bristol', 'Bristol', 'Brugge - Energie Actieplan Brugge (Dutch) ', 'Budapest Fováros XIX. Kerület', 'Buenos Aires', 'Burlingame', 'Burlington', 'Bursa', 'Byron Shire', 'Cajnice - Akcioni Plan Energijski Odr', 'Calgary', 'Calgary climate-resilience-plan', 'Cambridge', 'Cape Town', 'Carona - SEAP Carona (Italian) ', 'Cartura - PAES Cartura (Italian) ', 'Casalserugo - PAES Casalserugo (Italian) ', 'Cervia - Cervia Citt', 'Charlotte', 'Charlotte', 'Cheremule - Energy Plan Cheremule (Italian)', 'Chicago', 'Cincinnati', 'City of Santa Cruz Climate Action Plan', 'Cleveland', 'Columbia', 'Columbus', 'Commune de Paliseul - Paedc Paliseul (French) ', 'Comunità pioniera di Arborea - PAES - Comunit', 'Copenhagen', 'Copenhagen - SEAP (Danish) ', 'Corsano - Corsano Sostenibile - Verso Il 202 A Basse Emissioni Di Co2 (Italian) ', 'Cupertino Climate Action Plan', 'Dallas', 'Davis', 'Delft - Delft Energy Neutral 2050  ', 'Denver', 'Denver', 'Dénia - SEAP Of Dnia (Spanish) ', 'Dilbeek - Dilbeek Klimaatactieplan (Dutch) ', 'Dossena - My SEAP Dossena (Italian) ', 'Dublin', 'Dundee - Dundee Climate Action Plan ', 'Durbuy - PAEDC Durbuy (French) ', 'Eau Claire', 'Edina', 'Edmonton', 'Eilat ISRAEL - Eilat Municipality Plan To Reduce Greenhouse Gas Emission ', 'Elini - Action Plan Local Arzana Elini (Italian) ', 'Elsinore', 'Elsinore', 'Emeryville', 'Emeryville CAP 2016 Final', 'Erie County', 'Espoo', 'Espoo - Climate Programme 2016-2020', 'Essen - Fortschreibung 2013 (German) ', 'Eugene', 'Eugene', 'Evanston', 'Fermo - SEAP', 'Flagstaff', 'Fontanafredda - PAES Comune Di Fontanafredda (Italian) ', 'Fort Collins', 'Frankenthal - Integrated Climate Protection Concept ', 'Frederikshavn - Masterplan For 100', 'Fremont', 'Gagliano del Capo - Gagliano Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) ', 'Gela - Relazione Gela (Italian) ', 'Genk - Klimaatplan 2030 (Dutch) ', 'Giave - Energy Plan Giave (Italian) ', 'Glasgow', 'Gorga - SEAP Of Gorga (Spanish) ', 'Gothenburg - The Energy Efficient City ', 'Granze (Pd) - Italy - PAES Granze (Italian) ', 'Greater Manchester', 'Groningen - Groningen Energizes ', 'Guelph', 'Haarlem - Gemeentelijke Co2-Monitor (Dutch) ', 'Halifax', 'Halle - Halle(N) In Actie Voor Het Klimaat! (Dutch) ', 'Hanau - Kommunales Klimaschutzkonzept Hanau (German) ', 'Hannover - SEAP (German) ', 'Hayward', 'Hebron - Hebron SEAP ', 'Heidelberg', 'Heidelberg - Co2-Bilanzierung 2012 Bis 2015 Sowie Evaluation Des Masterplan 100', 'Helsinki - Kest', 'Herbeumont - PAEDC Herbeumont (French) ', 'Hlybokaje - SEAP (Russian) ', 'Hong Kong', 'Houston', 'Houston', 'Høje-Taastrup', 'Høje-Taastrup', 'Indianapolis', 'Ios (Aegean Islands) - SEAP (Greek) ', 'Isola D’Elba - PAES Isola D', 'Isola di Fondra - SEAP Isola Di Fondra (Italian) ', 'Izegem - Goedgekeurd SECAP (Dutch) ', 'Jászberény Városi Önkormányzat - Jszberny Fenntarthat Energia Akciterve (Hungarian) ', 'Joensuu - SEAP Joensuu 2015 Update ', 'Jolanda di Savoia - PAES (Italian) ', 'Jurmala - SEAP For Jurmala City For 2013-2020 (Latvian) ', 'Kaiserslautern - SEAP (German) ', 'Kampala Climate Change Action', 'Kansas', 'Kéa (Aegean Islands) - SEAP (Greek) ', 'Knoxville', 'Kortenaken - Klimaatactieplan Kortenaken (Dutch) ', 'Korthi (Aegean Islands) - SEAP (Greek) ', 'Kozloduy - Energy Action Plan (Bulgarian) ', 'Kristianstad', 'Kristianstad', 'Krško - SEAP (Slovenian) ', 'Kruibeke - Kruibeke Klimaatneutraal (Dutch) ', 'Kungsbacka - Klimatstrategi For Kungsbacka Kommun (Swedish) ', 'KwaDukuza', 'LA', 'La Puebla de Cazalla - SEAP Of La Puebla De Cazalla (Sevilla - Spain) (Spanish) ', 'Landen - Gemeentelijk Klimaatactieplan Landen (Dutch) ', 'Las Torres de Cotillas - Firma Compromisos (Spanish) ', 'Leeds - Leeds City Council SEAP ', 'Lennik - Klimaatactieplan Gemeente Lennik (Dutch) ', 'Lessebo - Energi', 'Leuven - SEAP (Dutch) ', 'Lexington', 'Liedekerke - Gemeentelijk Klimaatplan Liedekerke (Dutch) ', 'Linter - Klimaatactieplan Gemeente Linter (Dutch) ', 'Lipsi (Aagen Islands) - SEAP (Greek) ', 'Lisbon', 'Lisbon', 'Lisbon', 'Lisbon - PAES De Lisboa (Portuguese) ', 'Ljubljana', 'Loiri Porto San Paolo - Loiri Porto San Paolo Sostenibile (Italian) ', 'London', 'London', 'London', 'London', 'Louiseville', 'Louisiana JBE-2020-18-Climate-Initiatives-Task-Force', 'Louisville', 'Lörrach - Klimaneutrale Stadt Lorrach Endbericht (German) ', 'Luleå - SEAP Lule (Swedish) ', 'Macerata - PAES Del Comune Di Macerata (Italian) ', 'Macerata Campania - PAES Macerata Campania (Italian) ', 'Maldegem - SEAP Maldegem Actieplan (Dutch) ', 'Maltepe - Maltepe Municipality SEAP (Turkish) ', 'Manchester', 'Mantova - Mantova SEAP Pubiished (Italian) ', 'Medford', 'Melbourne', 'Melbourne', 'Menjez - Menjez', 'Merlara - PAES Merlara (Italian) ', 'Mexico', 'Mezzoldo - SEAP Document Mezzoldo (Italian) ', 'Mississauga', 'Mississauga Climate Change Action Plan', 'Moio de Calvi - SEAP Mio De', 'Monistrol de Calders - Pla D', 'Monrupino-Repentabor - PAES Di Monte Di Malo (Italian) ', 'Monte di Malo - PAES Di Monte Di Malo (Italian) ', 'Montejícar - Informe De Seguimiento PAES 2012-2020 (Spanish) ', 'Monteleone Rocca Doria - PAES (Italian) ', 'Monterenzio - PAES Monterenzio (Italian) ', 'Morciano di Leuca - Morciano Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) ', 'Mornington Peninsula', 'Moruzzo - Relazione Tecnico Illustrativa (Italian)', 'Moura - SEAP Moura (Portuguese) ', 'Münster - SEAP (German) ', 'Nablus - Nablus SEAP ', 'Nevele - Duurzaam Energieactieplan Gemeente Nevele (Dutch) ', 'New Bedford', 'New Orleans', 'New York City', 'Nikopol - SEAP', 'Nilüfer - SEAP Monitoring Report (Dutch) ', 'Nisyros (Aegean Islands) - SEAP (Greek) ', 'Northhampton', 'Offida - Sustainable Energy And Climate Action Plan - Mitigation (Italian) ', 'Orebro', 'Orebro', 'Orlando', 'Orlando', 'Ornica - SEAP Document Ornica (Italian) ', 'Oslo', 'Ossana - PAES Comune Di Ossana (Italian) ', 'Oulu - SEAP Of Oulu Under Covenant Of Mayors (Finnish) ', 'Oxford - Climate Emergency Strategy Support ', 'Palma - Pla D', 'Palo Alto', 'Palo Alto', 'Pantelleria - PAES Del Comune Di Pantelleria (Italian) ', 'Paola - PAES (Italian) ', 'Paris', 'Patù - Patu', 'Pedro Abad - PAES (Spanish) ', 'Pellizzano - PAES Comune Di Pellizzano (Italian) ', 'Peñarroya-Pueblonuevo - Plan De Accin Por El Clima Y La Energa Sostenible (Spanish) ', 'Philadelphia', 'Philadelphia', 'Piazzatorre - SEAP Document Piazzatorre (Italian) ', 'Piazzolo - SEAP Document Piazzolo (Italian) ', 'Piedmont', 'Pittsburgh', 'Pittsburgh', 'Plymouth', 'Pollina - Relazione Pollina (Italian) ', 'Pontecchio Polesine - PAES Pontecchio Polesine (Italian) ', 'Porsgrunn - Climate Actionplan For Grenland Included Industry (Norwegian) ', 'Portland', 'Providence', 'Providence', 'Region Zuid-West-Vlaanderen - Regionaal Duurzame Energie Actieplan 2020 (Dutch) ', 'Reykjavík', 'Riga', 'Riga - Riga City SEAP (SEAP) For 2014-2020 ', 'Riner - Pla D', 'Ringkøbing-Skjern - Strategic Energy Plan For Ringkbing-Skjern Muncipality - Energy 2020 - 2015-2018 ', 'Roncobello - SEAP Document Roncobello (Italian) ', 'Roveredo In Piano - PAES Del Comune Di Roveredo In Piano - Relazione Tecnico-Illustrativa (Italian) ', 'Sacramento', 'Saint-Nicolas - Plan D', 'Salt Lake City', 'Salve - Salve Sostenibile - Verso Il 2020 A Basse Emissioni Di Co2 (Italian) ', 'Samsø - SEAP Island Of Samso', 'San Carlos', 'San Francisco', 'San Francisco', 'San Giorgio di Nogaro - PAES Del Comune Di San Giorgio Di Nogaro - Relazione Tecnico Illustrativa (Italian) ', 'San Isidro', 'San Jose', 'San Jose', 'San Pietro Viminario (Pd) - PAES San Pietro Viminario (Italian) ', 'San Polo d', 'Sant', 'Sant', 'Sant', 'Santa Brigida - SEAP Document Santa Brigida (Italian) ', 'Santa Cruz', 'Santa Maria Nuova - Piano Dazione Per Lenergia Sostenibile Del Comune Di Santa Maria Nuova (Italian) ', 'Santiago Action Plan -COP25 - final', 'Sarasota', 'Sarasota', 'Sartirana Lomellina - PAES Del Comune Di Sartirana Lomellina (Italian)', 'Saskatoon', 'Senigallia - SEAP Of Senigallia (Italian) ', 'Serre - PAES Del Comune Di Serre  (Italian) ', 'Seulo - PAES Della Comunit Di Seulo (Italian) ', 'Singapore', 'Skive - Klima ', 'Skovde', 'Skovde', 'Skyros Island - SEAP Of Municipality Of Skyros (Greek) ', 'Socchieve - PAES Del Comune Di Socchieve (Italian) ', 'Solesino - PAES Solesino (Italian) ', 'Somerville', 'Somma Lombardo - Somma Lombardo SEAP (Italian) ', 'Somoniyon - SEAP Of Somoniyon ', 'Sonama', 'South Tyneside - A SEAP For South Tyneside ', 'St Catharines ', 'St Louis', 'St Louis', 'Stockholm', 'Stockholm', 'Sydney', 'Sønderborg - Projectzero Masterplan 2029 ', 'Tacoma', 'Tacoma', 'Tacoma', 'Tainan', 'Tainan City Climate Action 2016', 'Taleggio - PAES Comune Di Taleggio (Italian) ', 'Tampere - Pormestareiden Ilmastositoumuksen Kestvn Energiankytn Ohjelma (Finnish) ', 'Tàrbena - SEAP Of Trbena (Spanish) ', 'Teulada - SEAP Of Teulada (Spanish) ', 'The Espoo Story in English', 'Tibi - SEAP Of Tibi (Spanish) ', 'Tilburg - Klimaataanpak 2013-2020 (Dutch) ', 'Tirana - SEAP Of The City Of Tirana ', 'Tokyo', 'Toronto', 'Trondheim', 'Trondheim', 'Trondheim - SEAP (Norwegian) ', 'Tulkarm - Tulkarem SEAP', 'Turku', 'Umea', 'Unione dei Comuni NET (Nord Est Torino) - SEAP Of The Union Of Municipalities (Italian) ', 'Uppsala', 'Upssala Climate and Energy Programme 2014-2023', 'Urbana', 'Urbana - PAES Urbana (Italian) ', 'Urbino - PAES Del Comune Di Urbino ', 'Utrecht - Utrecht Energy Plan ', 'Vaasa - City Of Vaasa SEAP (Finnish) ', 'Valtorta - Sustaianble Energy Action Plan Valtorta (Italian) ', 'Vancouver', 'Vantaa - Vantaan Kaupungin Kets', 'Växjö - Energy Plan For Vxj Municipality ', 'Vedeseta - SEAP Vedeseta (Italian) ', 'Victoria', 'Victoria Climate Action Plan', 'Vilkaviškis - SEAP ', 'Villa Literno - PAES E Liternum (Italian) ', 'Villa Verde - PAES Della Comunit Di Villa Verde (Italian) ', 'Villanova Tulo - PAES (Italian) ', 'Villasimius - PAES Della Comunit Di Villasimius (Italian) ', 'Ville de Nivelles - Plan Dactions Nergie Durable ', 'Vimodrone - PAES (Italian) ', 'Vogogna - PAES Di Vogogna (Italian) ', 'Västervik', 'Västervik', 'Wallonie Picarde Energie Positive - Groupe Wallonie Picarde Energie Positive (French) ', 'Washington D.C.', 'Wezembeek-Oppem - Gemeentelijk Klimaatactieplan (Dutch) ', 'Winnipeg', 'Wollongong', 'Wyndham', 'eThekweni', 'Ærø - Visionsplan For Rs Energiforsyning (Danish) ']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(os.listdir('sample_data/text_jsons/')))\n",
    "print(df['city'].sort_values().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text preprocessing using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LanguageDetector in module spacy_langdetect.spacy_langdetect:\n",
      "\n",
      "class LanguageDetector(builtins.object)\n",
      " |  LanguageDetector(language_detection_function=None)\n",
      " |  \n",
      " |  Fully customizable language detection pipeline for spaCy.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      language_detection_function: An optional custom language_detection_function. (Default None).\n",
      " |                                   If None uses, langdetect package to detect language\n",
      " |  \n",
      " |  # writing a custom language_detection_function:\n",
      " |      The function must take in a spacy Doc or Span object only as input and can return the detected language.\n",
      " |      This is stored in Doc._.language, Span._.language and Token._.language attributes.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, doc)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, language_detection_function=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "help(LanguageDetector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthsachdeva/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "  1%|          | 3/384 [00:00<00:15, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing from scrtch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 100/384 [05:53<16:43,  3.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-925d85b4c6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPROCESSED_DOCS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing from scrtch...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_doc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/carbon_zero_nlp/czero_nlp/lib/python3.8/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "tqdm.pandas()\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "if not PROCESSED_DOCS:\n",
    "    print('Processing from scrtch...')\n",
    "    df['raw_doc'] = df['raw_text'].progress_apply(nlp)\n",
    "    detector = LanguageDetector()\n",
    "\n",
    "    # df['raw_language'] = df['raw_doc'].progress_apply(lambda doc: detector(doc)._.language['language'])\n",
    "    def get_doc(row):\n",
    "        if row['translated_text'] is None:\n",
    "            # Language detection has many false english detections, so I'll just use the translated documents.\n",
    "            return row['raw_doc']\n",
    "        elif row['translated_text'] is not None:\n",
    "            return nlp(row['translated_text'])\n",
    "        else:\n",
    "            print('None')\n",
    "            return None\n",
    "        \n",
    "    df['doc'] = df.progress_apply(get_doc, axis=1)\n",
    "    df.to_pickle('processed_apr7.pkl')\n",
    "else:\n",
    "    print('Loading pickle file')\n",
    "    df = pd.read_pickle('processed_apr7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = LanguageDetector()\n",
    "\n",
    "df['raw_language'] = df['raw_doc'].progress_apply(lambda doc: detector(doc)._.language['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw_language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untranslated = df[(df['raw_language']!='en') & df['translated_text'].isnull()]\n",
    "df = df[~(df.translated_text.isnull() & (df['city'].isin(untranslated['city'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_texts = df[(df['raw_language']=='en') | df2['translated_text'].notnull()] \n",
    "len(inp_texts['city'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def get_city_name(row):\n",
    "    \"\"\"Takes row and gives cleaned city name\"\"\"\n",
    "    if row['translated_text'] is not None:\n",
    "        city = row['path'].split('/')[-1].split('-')[0].split(',')[0]\n",
    "        if city.endswith('.json'):\n",
    "            city = city.split('_')[0]\n",
    "        return city\n",
    "    else:\n",
    "        return row['city']\n",
    "    \n",
    "def remove_filler(s):\n",
    "    \"\"\"Remove filler words from plan name string\"\"\"\n",
    "    rep = [\n",
    "        'Action',\n",
    "        'Plan',\n",
    "        'Climate',\n",
    "        'Emergency',\n",
    "        '2016',\n",
    "        'Final',\n",
    "        'JBE-2020-18-Climate--Initiatives-Task-Force',\n",
    "        'JBE-2020-18--Initiatives-Task-Force',\n",
    "        'strategy',\n",
    "        'Neutral',\n",
    "        'Strategy',\n",
    "        '-COP25 -',\n",
    "        'and Energy Programme 2014-2023',\n",
    "        'Energie Positive',\n",
    "        'Energie Positive',\n",
    "        'CAP',\n",
    "        '-CEP-CLEAN-003',\n",
    "        'climate-resilience-plan',\n",
    "        'Fovaros XIX. Kerulet, Kispest Onkormanyzata',\n",
    "        'City of', \n",
    "        'Change',\n",
    "        'final'\n",
    "    ]\n",
    "    for w in rep:\n",
    "        s = s.replace(w, '')\n",
    "    return s.strip()\n",
    "\n",
    "def remove_trailing(s):\n",
    "    return s.split(',')[0]\n",
    "\n",
    "def rename(os):\n",
    "    mapping = {\n",
    "        'AEro': 'Ærø',\n",
    "        'Beniardà': 'Beniardà',\n",
    "        'Comunita pioniera di Arborea': 'Comunità pioniera di Arborea',\n",
    "        'LA': 'Los Angeles', \n",
    "        'Mexico': 'Mexico City', \n",
    "        'Sonama': 'Sonoma',\n",
    "        'Belvì': 'Belvì',\n",
    "        'Budapest Fováros XIX. Kerület': 'Budapest',\n",
    "        'Comunità pioniera di Arborea': 'Comunità pioniera di Arborea',\n",
    "        'Dénia': 'Dénia',\n",
    "        'Granze (Pd)': 'Granze (Pd) - Italy',\n",
    "        'Kéa (Aegean Islands)': 'Kéa (Aegean Islands)',\n",
    "        'Krško': 'Krško',\n",
    "        'Lörrach': 'Lörrach',\n",
    "        'Luleå': 'Luleå',\n",
    "        'Monrupino': 'Monrupino-Repentabor',\n",
    "        'Montejícar': 'Montejícar',\n",
    "        'Mornington Peninsula': 'Mornington Peninsula Shire',\n",
    "        'Münster': 'Münster',\n",
    "        'Nilüfer': 'Nilüfer',\n",
    "        'Northhampton': 'Northampton',\n",
    "        'Patù': 'Patù',\n",
    "        'Peñarroya': 'Peñarroya-Pueblonuevo',\n",
    "        'Region Zuid': 'Region Zuid-West-Vlaanderen',\n",
    "        'Reykjavík': 'Reykjavík',\n",
    "        'Ringkøbing': 'Ringkøbing-Skjern',\n",
    "        'Saint': 'Saint-Nicolas',\n",
    "        'San Jose': 'San José',\n",
    "        'San Polo d_Enza': \"San Polo d'Enza\",\n",
    "        'Sant_ Urbano': \"Sant'urbano\",\n",
    "        'Sant_Anna Arresi': \"Sant'Anna Arresi\",\n",
    "        'Sant_Elena': \"Sant'Elena\",\n",
    "        'St Catharines': 'St. Catharines',\n",
    "        'St Louis': 'St. Louis',\n",
    "        'Tàrbena': 'Tàrbena',\n",
    "        'Umea': 'Umeå',\n",
    "        'Upssala': 'Uppsala',\n",
    "        'Växjö': 'Växjö',\n",
    "        'Vilkaviškis': 'Vilkaviškis',\n",
    "        'Wezembeek': 'Wezembeek-Oppem',\n",
    "        'eThekweni': 'Durban',\n",
    "        'Wallonie Picarde': 'Wallonie picarde Energie Positive',\n",
    "        'Tainan City': 'Tainan',\n",
    "        'The Espoo Story in English': 'Espoo',\n",
    "        'Kansas': 'Kansas City',\n",
    "        'Jászberény Városi Önkormányzat':  'Jaszbereny Varosi Onkormanyzat',\n",
    "        'Skovde':'Skövde'\n",
    "    }\n",
    "\n",
    "    s = deepcopy(os)\n",
    "    for og in mapping:\n",
    "        s = s.replace(og, mapping[og])\n",
    "    return s\n",
    "\n",
    "inp_texts['city_name'] = inp_texts.apply(get_city_name, axis=1)\n",
    "inp_texts['city_name'] = inp_texts['city_name'].apply(\n",
    "    remove_trailing).apply(remove_filler).apply(rename)\n",
    "inp_texts['city_name'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_names.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(l):\n",
    "    if len(l) > 2 and l[-1] == l[-3]:\n",
    "        o = l[:-2]\n",
    "    elif len(l) > 1 and l[-1] == l[-2]:\n",
    "        o = l[:-1]\n",
    "    else:\n",
    "        o = l\n",
    "    return ' '.join(o)\n",
    "\n",
    "meta.name = meta.name.str.split().apply(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.name = meta.name.apply(\n",
    "    remove_trailing).apply(remove_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Clean City Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_names = pd.Series(json.load(open('/Users/siddharthsachdeva/Downloads/final_city_list.json')))\n",
    "#clean_names['cleaned_name'] = clean_names['name'].str.split(',').apply(lambda ps: ps[0])\n",
    "#clean_names['cleaned_name'].sort_values().tolist()\n",
    "len(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvc = meta['name'].value_counts()\n",
    "multiple = fvc[fvc>1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.groupby('name').aggregate(lambda s: s.iloc[0] if len(s.unique()) == 1  else s.tolist()).reset_index()\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['cleaned_name'] = meta['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_texts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_texts['cleaned_name'] = inp_texts['city_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(meta, right=inp_texts, on='cleaned_name', how='outer')\n",
    "len(data['cleaned_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine plans for the same city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['doc'].notnull()]\n",
    "len(data['cleaned_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = data['name'].value_counts()\n",
    "vc[vc>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def combine(city_reports):\n",
    "    \"\"\"Combine rows that have the same city\"\"\"\n",
    "    res = city_reports[~city_reports['raw_text'].duplicated()]\n",
    "    if len(res) == 1:\n",
    "        return res\n",
    "    new = dict()\n",
    "    for col in city_reports.columns:\n",
    "        data = city_reports[col]\n",
    "        data = data[data.notnull()]\n",
    "        data = data[~data.apply(str).duplicated()]\n",
    "        if len(data) == 0:\n",
    "            new[col] = np.nan\n",
    "        elif len(data) == 1:\n",
    "            new[col] = data.iloc[0]\n",
    "        elif col == 'raw_text':\n",
    "            new[col] = '\\n\\n\\n'.join(city_reports[col].tolist())\n",
    "        elif col == 'doc':\n",
    "            new[col] = nlp('\\n\\n\\n'.join(city_reports['raw_text'].tolist()))\n",
    "        else:\n",
    "            new[col] = data.tolist()\n",
    "    return pd.DataFrame([pd.Series(new)])\n",
    "\n",
    "data = data.groupby('name').progress_apply(combine).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge city characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data = data['region'].value_counts(dropna=False).iloc[::-1]\n",
    "region_data.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country2missing_regions = {\n",
    "    'ITA': 'Europe',\n",
    "    'USA': 'North America',\n",
    "    'BEL': 'Europe',\n",
    "    'GBR': 'Europe',\n",
    "    'PRT': 'Europe',\n",
    "    'FIN': 'Europe',\n",
    "    'SVN': 'Europe',\n",
    "    'BLR': 'Europe',\n",
    "    'LVA': 'Europe',\n",
    "    'LBN': 'Middle East and North Africa',\n",
    "    'PRT': 'Europe',\n",
    "    'HUN': 'Europe',\n",
    "    'UKR': 'Europe',\n",
    "    'NOR': 'Europe',\n",
    "    'ISL': 'Europe',\n",
    "    'DNK': 'Europe',\n",
    "    'IRL': 'Europe',\n",
    "    'ISR': 'Middle East and North Africa',\n",
    "    'PSE': 'Middle East and North Africa',\n",
    "    'TUR': 'Middle East and North Africa',\n",
    "    'ISR': 'Middle East and North Africa',\n",
    "    'UGA': 'Sub-Saharan Africa',\n",
    "    'ZAF': 'Sub-Saharan Africa',\n",
    "    'TWN': 'East Asia and the Pacific',\n",
    "    'SGP': 'East Asia and the Pacific',\n",
    "    'JPN': 'East Asia and the Pacific',\n",
    "    'CHN': 'East Asia and the Pacific',\n",
    "    'MEX': 'North America',\n",
    "    'ESP': 'Europe',\n",
    "    'CAN': 'North America',\n",
    "    'NLD': 'Europe',\n",
    "    'DEU': 'Europe',\n",
    "    'CHL': 'South America',\n",
    "    'BRA': 'South America',\n",
    "    'ARG': 'South America',\n",
    "    'AUS': 'East Asia and the Pacific',\n",
    "    'NZL': 'East Asia and the Pacific'\n",
    "}\n",
    "\n",
    "data.loc[data['region'].isnull(), 'region'] = data[data['region'].isnull()]['iso'].map(country2missing_regions)\n",
    "data['region'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = data.region.value_counts()[::-1]\n",
    "region_counts.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set tgt variables for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.econ_wide_net_zero = inp_data.econ_wide_net_zero.notnull()\n",
    "inp_data.econ_wide_net_zero.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '1,4,1,2,4,1,4,1'\n",
    "fix_tgts = lambda s: ','.join(set([x.strip() for x in s.split(',')]))\n",
    "fix_tgts(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_tgt(tgt):\n",
    "    if isinstance(tgt, list):\n",
    "        return convert_tgt(','.join(sorted([x for x in tgt if x is not np.nan])))\n",
    "    elif isinstance(tgt, str):\n",
    "        return ','.join(sorted(set([x.strip() for x in tgt.split(',')])))#','.join(sorted(list(set([x.strip() for x in tgt.split(',')]))))\n",
    "    else:\n",
    "        return tgt\n",
    "\n",
    "inp_data.net_zero_target_status = inp_data.net_zero_target_status.apply(convert_tgt)\n",
    "inp_data.net_zero_target_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.net_zero_target_status.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data['legislative_commitment'] = inp_data.net_zero_target_status.str.contains('2')\n",
    "inp_data['legislative_commitment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data[inp_data['percent_reduction'].apply(type) == list].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduction_tgt(pct_reduction):\n",
    "    if isinstance(pct_reduction, str):\n",
    "        pct_reduction = json.loads(pct_reduction)\n",
    "    if isinstance(pct_reduction, list):\n",
    "        return max(pct_reduction)\n",
    "    elif np.isnan(pct_reduction):\n",
    "        return 0\n",
    "    else:\n",
    "        return pct_reduction\n",
    "    \n",
    "inp_data['AGGRESSIVE_TARGET'] = inp_data['percent_reduction'].apply(get_reduction_tgt) > 80\n",
    "inp_data['AGGRESSIVE_TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(city):\n",
    "    ps = city.lower().split(' ')\n",
    "    cs = []\n",
    "    for i in range(len(ps)):\n",
    "        for j in range(i+1, len(ps)+1):\n",
    "            cs.append(' '.join(ps[i:j]))\n",
    "    \n",
    "    return cs\n",
    "\n",
    "combinations('new york city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Raw Text into Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = set(inp_data[inp_data['city_name'].notnull()]['city_name'].apply(combinations).explode()).union({'bay'})\n",
    "all_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = set(inp_data[inp_data['country'].notnull()]['country'].apply(combinations).explode())\n",
    "all_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'york' in all_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set([\n",
    "    'page',\n",
    "    'ave',\n",
    "    'nov'\n",
    "    'montana',\n",
    "    'sardinia',\n",
    "    'ooo'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_words = all_cities.union(all_countries).union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_token(tok):\n",
    "    not_a_city = tok.text.lower() not in ignore_words \n",
    "    return tok.has_vector and not tok.is_punct and tok.is_alpha and len(tok.text) > 2 and not_a_city and tok.pos_ != 'PRON' and tok.lemma_.lower() != '-pron-'\n",
    "\n",
    "for sent in inp_data['doc'].iloc[2].sents:\n",
    "    toks = [tok for tok in sent if include_token(tok)]\n",
    "    if len(toks):\n",
    "        print('Got')\n",
    "        print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_tokens(doc):\n",
    "    if doc is not np.nan:\n",
    "        return [tok for tok in doc if include_token(tok)]\n",
    "    else:\n",
    "        return [] \n",
    "\n",
    "inp_data['tokens'] = inp_data['doc'].progress_apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_tokens(tokens):\n",
    "    return [tok.lemma_.lower() for tok in tokens]\n",
    "\n",
    "inp_data['lemmatized_tokens'] = inp_data['tokens'].apply(get_lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out shorter documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inp_data['lemmatized_tokens'].apply(len) < 100).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data = inp_data[(inp_data['lemmatized_tokens'].apply(len) > 100)]\n",
    "inp_data = inp_data[~inp_data.raw_text.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data['econ_wide_net_zero'].apply(bool).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.econ_wide_net_zero.notnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "help(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', tokenizer=dummy, preprocessor=dummy, min_df=0.05)\n",
    "cv_2grams = CountVectorizer(stop_words='english', tokenizer=dummy, preprocessor=dummy, ngram_range=(1,2), min_df=0.1)\n",
    "cv.fit(inp_data['lemmatized_tokens'])\n",
    "cv_2grams.fit(inp_data['lemmatized_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data['region'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_2grams.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv.transform(inp_data['lemmatized_tokens'])\n",
    "x_2g = cv_2grams.transform(inp_data['lemmatized_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "help(TfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True, sublinear_tf=True)\n",
    "normalized_x = tfidf.fit_transform(x)\n",
    "normalized_x2g = tfidf.fit_transform(x_2g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize Intermediate data structures for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data['lemmatized_text'] = inp_data['lemmatized_tokens'].apply(lambda l: ' '.join(l))\n",
    "inp_data['doc_lengths'] = inp_data['lemmatized_tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data[['city_name', 'region', 'coordinator_name', 'doc_lengths', \n",
    "          'econ_wide_net_zero', 'AGGRESSIVE_TARGET']].to_csv('serialize/inp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('serialize/x.pickle', 'wb') as out:\n",
    "    pickle.dump(x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialize/x_2g.pickle', 'wb') as out:\n",
    "    pickle.dump(x_2g, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialize/normalized_x.pickle', 'wb') as out:\n",
    "    pickle.dump(normalized_x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialize/normalized_x2g.pickle', 'wb') as out:\n",
    "    pickle.dump(normalized_x2g, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialize/vocabulary.json', 'w') as out:\n",
    "    json.dump(cv.vocabulary_, out)\n",
    "    \n",
    "with open('serialize/vocabulary_2g.json', 'w') as out:\n",
    "    json.dump(cv_2grams.vocabulary_, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czero_nlp",
   "language": "python",
   "name": "czero_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
